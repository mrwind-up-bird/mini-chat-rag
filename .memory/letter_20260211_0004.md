# Checkpoint: Product Feature Proposals Complete

**Date**: 2026-02-11
**Author**: Product Evangelist
**Task**: #3 -- Research and propose new features for MiniRAG

## Summary

Completed deep exploration of the entire MiniRAG codebase (all models, API routes, services, workers, dashboard, widget) and researched the competitive RAG platform landscape (Ragie, Vectara, Nuclia, LangChain, LlamaIndex, AnythingLLM, ChatBase, CustomGPT).

## Deliverable

Wrote `.memory/product_proposals.md` with 7 feature proposals ranked by impact-to-effort ratio:

1. **Streaming Chat Responses (SSE)** - M effort, #1 priority - transforms every chat interaction
2. **Scheduled Source Re-Ingestion** - M effort - makes knowledge bases self-updating
3. **Webhooks for Key Events** - M effort - makes MiniRAG composable with external tools
4. **Conversation Export & Feedback Analytics** - S effort, #2 priority - unlocks quality monitoring
5. **Prompt Playground (A/B Testing)** - L effort - genuinely differentiated feature
6. **Multi-Language Support** - L effort - important for German market (mini-rag.de)
7. **Web Crawler / Sitemap Import** - L effort - "website to chatbot in 60 seconds" story

## Key Insights

- MiniRAG's multi-tenant architecture and parent/child source model are already well-designed for features like web crawling and batch ingestion
- The existing feedback field on messages (Message.feedback) is an underutilized asset -- surfacing it through analytics would be quick and high-impact
- LiteLLM already supports streaming (stream=True), making SSE implementation relatively straightforward
- The widget's Shadow DOM isolation is excellent -- streaming would make it genuinely competitive with commercial offerings
- The ARQ worker infrastructure is already in place for scheduled tasks
