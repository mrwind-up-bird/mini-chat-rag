# Checkpoint: Add in-memory TTL caching to stats endpoints

**Date**: 2026-02-11
**Task**: #4 — Add rate limiting or caching to stats endpoints
**Status**: Completed

## What was done

Added lightweight in-memory TTL caching (30s default) to all stats endpoints to avoid re-running aggregate SQL queries on rapid repeated requests (e.g., dashboard page loads, refreshes).

## Changes

### New file: `app/core/cache.py`
- Simple dict-based TTL cache using `time.monotonic()`
- Functions: `get(key, ttl)`, `put(key, value)`, `invalidate(key)`, `clear()`
- No external dependencies required

### Modified: `app/api/v1/stats.py`
- Added `from app.core import cache` import
- Each endpoint now checks `cache.get()` before running queries
- Cache keys: `("stats", endpoint_name, tenant_id, params...)` — tenant-scoped
- On cache miss: run query, `cache.put()` the result, return it
- Endpoints cached: overview, usage, usage/by-bot, usage/by-model, cost-estimate
- Pricing endpoint not cached (just reads an in-memory dict, already instant)

### Modified: `tests/conftest.py`
- Added `cache.clear()` before and after each test client fixture to prevent cross-test interference

### Modified: `tests/test_stats.py`
- Added `test_stats_caching` — verifies repeated calls return identical data

## Test results
All 88 tests passing (87 previous + 1 new caching test).
